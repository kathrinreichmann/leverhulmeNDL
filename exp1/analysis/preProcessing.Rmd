---
title: "FLO replication - Preprocessing "
author: "Eva"
date: "4/3/2020"
output:
  html_document:
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: 3
---



```{r loading libraries, echo=FALSE, message=FALSE}
library(tidyverse);
```

# clean WS, set WD 

```{r}
rm(list = ls());
```

Set your local working directory. This should be (and is assumed to be in the rest of the code) the highest point in your local folder:
```{r}
localGitDir <- 'C:/Users/eva_v/Documents/GitHub/leverhulmeNDL'

```
```{r load stimuli set}
fribbleSet <- read.csv(paste(localGitDir, "/exp1/stimuli/stimuli.csv", sep = ""), 
                       header = T,
                       colClasses=c("cueID"="factor",
                        "bodyShape"="factor",
                        "label"="factor",
                        "fribbleID"="factor"
                        ));
```


# Check stimuli set
It's important to check that every fribble is unique in the way its features are assembled within each category.
Feature position and identity are coded into cueID.

I'm going to check whether the combination of cues used to build the fribble is unique by filtering for n > 1:

```{r check for duplicates}

fribbleSet %>%
  group_by(category, cueID) %>%
  count() %>%
  filter(n > 1);
```

Great, each Fribble is unique!

# Load data

List the files present in the folder, and load them.

```{r list files}
df <- list.files(paste(localGitDir, "/exp1/data/rawData/", sep = "")); 

```

We have `r length(df)` files.

```{r load files}
for (i in 1:length(df)){
  gsub(".csv$", "", df[i]) -> id
  assign(id, data.frame())
  read.csv(paste(localGitDir, "/exp1/data/rawData/", df[i], sep = ""),
           na.strings=c("","NA"),
           colClasses=c("presentedLabel"="factor",
                        "presentedImage"="factor",
                        "learningType"="factor",
                        "Trial.Type"="factor",
                        "Test.Part"="factor",
                        "Key.Press"="factor"
                        ))-> temp
  assign(paste0(id), temp)
};

rm(temp, df, i, id);
```

The dataset name is decided autonomously by Gorilla. Importantly, Gorilla produces a different file per condition, and codes the conditions by the last 4 letters.

- 2yjh is the FL learning

- q8hp is the LF learning

I'm going to rename them for clarity.

```{r rename dataset}
dataFL<-`data_exp_15519-v13_task-2yjh`
dataFL$Experiment.Version <- c(14)
dataFL2<-`data_exp_15519-v14_task-2yjh`
dataFL3<-`data_exp_15519-v15_task-2yjh`

rm(`data_exp_15519-v13_task-2yjh`)
rm(`data_exp_15519-v14_task-2yjh`)
rm(`data_exp_15519-v15_task-2yjh`)

dataLF <- `data_exp_15519-v13_task-q8hp`
dataLF$Experiment.Version <- c(14)
dataLF2 <- `data_exp_15519-v14_task-q8hp`
dataLF3 <- `data_exp_15519-v15_task-q8hp`

rm(`data_exp_15519-v13_task-q8hp`)
rm(`data_exp_15519-v14_task-q8hp`)
rm(`data_exp_15519-v15_task-q8hp`)

```

```{r merge datasets}
rbind(dataFL, dataFL2, dataFL3)-> dataFL
rbind(dataLF, dataLF2, dataLF3)-> dataLF

rm(dataFL2, dataFL3, dataLF2, dataLF3)
```


Gorilla's output is extremely messy. Each row is a screen event. However, we want only the events related to 1. the presentations of the fribbles and the labels 2. participants' response and 3. what type of tasks.

I have coded these info in some columns and rows that I'm going to select:


```{r column selection}
raw_dataFL<- dataFL[c('Participant.Private.ID', 'learningType', 'Test.Part' , 
         'presentedImage', 'presentedLabel', 'Reaction.Time', "Key.Press",
          'Trial.Type', 'Trial.Index', 'Correct', 'Experiment.Version')]

raw_dataLF<- dataLF[c('Participant.Private.ID', 'learningType', 'Test.Part' , 
         'presentedImage', 'presentedLabel', 'Reaction.Time', "Key.Press",
          'Trial.Type', 'Trial.Index', 'Correct', 'Experiment.Version')]


```

Select rows:

```{r rows selection}
rowsIwantTokeep <- c("learningBlock1", "learningBlock2", "learningBlock3",
                        "learningBlock4", "generalizationPL", "generalizationLP",
                        "randomDot", "contingencyJudgement")

raw_dataFL <- raw_dataFL %>% 
  filter(Test.Part %in% rowsIwantTokeep ) %>%
  rename(subjID = Participant.Private.ID, 
         learning = learningType,
         task = Test.Part, 
         fribbleID = presentedImage,
         label = presentedLabel, 
         rt = Reaction.Time, 
         resp = Key.Press, 
         trialType = Trial.Type,
         trialIndex = Trial.Index,
         acc = Correct)

raw_dataLF <- raw_dataLF %>% 
  filter(Test.Part %in% rowsIwantTokeep ) %>%
  rename(subjID = Participant.Private.ID, 
         learning = learningType,
         task = Test.Part, 
         fribbleID = presentedImage,
         label = presentedLabel, 
         rt = Reaction.Time, 
         resp = Key.Press, 
         trialType = Trial.Type,
         trialIndex = Trial.Index,
         acc = Correct)

rm(rowsIwantTokeep, dataFL, dataLF);
```

I'm going to merge both datasets, FL and LF, because we have anyway a column "learning" that can tell us which one is which.

```{r}
rbind(raw_dataFL, raw_dataLF)-> raw_data; 
rm(raw_dataFL, raw_dataLF);

```

# Check learning

Let's filter and check learning trials:

```{r learning filter}
learningBlocks <- c("learningBlock1", "learningBlock2", "learningBlock3", "learningBlock4");

learning <- raw_data %>% 
  filter(task %in% learningBlocks) 

learning <- droplevels(learning);
rm(learningBlocks)
```

## How many trials per participant? 
```{r check number of trials per ppts}
learning %>%                             
  group_by(subjID, learning) %>%    
  count() 
```

Great, 120 trials per participant, per learning.

Let's check whether the blocks' length varied across participants:

```{r check learning blocks length}
learning %>%                             
  group_by(subjID, task) %>%
  count()
```

Great! Each participant had a different amount of trials distributed across blocks. That's important because our random dot task was presented at the end of each block, and we wanted its presentation to be unpredictable.
Anyway, the sum of all the learning trials was always 120.


## Did we assign our learning randomly every couple of people?

```{r check learning randomization and grouping}
table(learning$subjID, learning$learning)
```
Kind of.
After chicking with Gorilla's suppoert: apparently, if a participant access Gorilla, but it's not allowed to start the experiment (e.g., the browser is not suitable), or leaves the session, this counts anyway for the randomisation.

The rows related to the presentation of fribbles and labels, inherit Gorilla's http address of where they are stored. Nothing I can do to change this in Gorilla, but we can clean the rows by those info like this:

```{r rows cleaning}
as.factor(gsub("/task/70033/56/asset/|/task/70033/57/asset/|/task/70033/58/asset/", "", learning$fribbleID))-> learning$fribbleID
as.factor(gsub(".jpg$", "", learning$fribbleID))-> learning$fribbleID

as.factor(gsub("/task/70033/56/asset/|/task/70033/57/asset/|/task/70033/58/asset/", "", learning$label))-> learning$label
as.factor(gsub(".mp3$", "", learning$label))-> learning$label
learning$resp <- as.factor('NA')
```

This is how the learning dataframe looks like now:

```{r}
head(learning);
```

```{r}
summary(learning);
```

Our fribbles were presented two times during learning. 

## Check if fribbles are presented > 2 times:
```{r}
learning %>%                             
  group_by(subjID, fribbleID) %>%    
  count() %>%
  filter(n >2)

```

None, perfect.

## Check whether there are fribbles presented only once:

```{r}
learning %>%                             
  group_by(subjID, fribbleID) %>%    
  count() %>%
  filter(n < 2)
```

Perfect.

## Check the association between the fribbles and the labels (high and low frequency with the correct labels)

Fribbles ID are coded in this way: 
e.g., 10175-> [1] is the category [01] is the number of the fribble [75] is the frequency.

In the column fribbleID we have the fribble presented, in the column label we have the sound played.

Association between fribbles and labels are fixed:

- category 1, regardless of the frequency, has the label: dep

- category 2, regardless of the frequency, has the label: bim

- category 3, regardless of the frequency, has the label: tob

I'm going to add a column for category, fribble number, and frequency, in order to check whether everything is okay:

We should have only 3 categories, presented twice per participant. Each category is made of 20 exemplars.

```{r check label fribble association during learning}
learning$category <- 0
learning[substr(as.character(learning$fribbleID), 1, 1)==1,]$category <- 1
learning[substr(as.character(learning$fribbleID), 1, 1)==2,]$category <- 2
learning[substr(as.character(learning$fribbleID), 1, 1)==3,]$category <- 3

(nrow(learning[learning$category==1,]) / length(unique(learning$subjID))) / 2
(nrow(learning[learning$category==2,]) / length(unique(learning$subjID))) / 2
(nrow(learning[learning$category==3,]) / length(unique(learning$subjID))) / 2

```
We have 15 high frequency and 5 low frequency exemplars x category:

```{r}
learning$frequency <- 25
learning[substr(as.character(learning$fribbleID), 4, 5)==75,]$frequency <- 75

(nrow(learning[learning$frequency==25,]) / length(unique(learning$subjID))) / 2
(nrow(learning[learning$frequency==75,]) / length(unique(learning$subjID))) / 2

```

Now let's check the fribble-label association:

```{r fribble-label table}
table(learning$category, learning$label, learning$frequency)
```

Okay, each label was associated to its correct fribble (coded here as category).


# Check Testing

I'm going to select the tests and clean the rows from Gorilla's http address:

```{r tests sanity check}
tests <- c("generalizationPL", "generalizationLP", "contingencyJudgement", "randomDot");

testing <- raw_data %>% 
  filter(task %in% tests)  


testing <- droplevels(testing);
rm(tests);

as.factor(gsub("/task/70033/56/asset/|/task/70033/57/asset/|/task/70033/58/asset/", "", testing$fribbleID))-> testing$fribbleID
as.factor(gsub(".jpg$", "", testing$fribbleID))-> testing$fribbleID

as.factor(gsub("/task/70033/56/asset/|/task/70033/57/asset/|/task/70033/58/asset/", "", testing$label))-> testing$label
as.factor(gsub(".mp3$", "", testing$label))-> testing$label


```

## Check test 1: Generalization from picture to labels

We filter the rows for this task, and clean both the resp and fribble columns.

```{r loading task}
generalizationPL <- testing %>%
  filter(task == 'generalizationPL') 
generalizationPL <- droplevels(generalizationPL);

as.factor(gsub("/task/70033/56/asset/|/task/70033/57/asset/|/task/70033/58/asset/", "", generalizationPL$resp))-> generalizationPL$resp
as.factor(gsub(".mp3$", "", generalizationPL$resp))-> generalizationPL$resp
as.factor(gsub(".jpg", "", generalizationPL$resp))-> generalizationPL$resp

gsub('[[:punct:]]|"', "", generalizationPL$label)-> generalizationPL$label 

as.factor(gsub('mp3', "_", generalizationPL$label))-> generalizationPL$label

```

### Check how many trials participants

```{r check num of trials}
generalizationPL %>%                             
  group_by(subjID) %>%  
  count() 
```

Great, 24 trials per participant. 

### Check whether participants saw a unique fribble:

```{r check fribbles num of presentation}
generalizationPL %>%                             
  group_by(subjID, fribbleID) %>%  
  count() %>%
  filter(n > 1)
```

Great! 

Integrate stimuli info.
In the file "fribbleSet" I have listed all the fribbles ID and their category, along with their cueIDs and body shape. I'm going to add those columns by merging the test file with the fribbleSet by fribbleID. The rest of the file is left untouched.

```{r merge with stimuli}
merge(generalizationPL, fribbleSet, by = 'fribbleID')-> generalizationPL;
generalizationPL$label.y <- NULL;

generalizationPL <- rename(generalizationPL, label = label.x);

```


Let's check the responses they made, just to see if they make sense.

For example, we want the resp column to be one of the labels.
```{r check resp column}
generalizationPL %>%                             
  group_by(subjID, resp) %>%  
  count() 
```

Great, some participant missed some trials (coded as NA), but that's okay.

So far, so good.


### Check trial/stimuli per category, per frequency, per subject

We have 24 trials per participant, but within those trials we *should* have 8 trials per category, 4 low frequency and 4 high frequency trials.

```{r}
head(table(generalizationPL$subjID, generalizationPL$category, generalizationPL$frequency))
```


Let's check the second task.

## Check test 2: Generalization from label to pictures

```{r from label to pics}
generalizationLP <- testing %>%
  filter(task == 'generalizationLP') 
generalizationLP <- droplevels(generalizationLP)
```

### How many trials per participant?

```{r}
generalizationLP %>%                             
  group_by(subjID) %>%  
  count() 
```

24 trials, great.



### Check whether participants saw a unique fribble

First let's clean the rows from Gorilla gibberish.

```{r}
as.factor(gsub('[[:punct:]]|"', "", generalizationLP$fribbleID))-> generalizationLP$fribbleID 

as.factor(gsub('jpg', "_", generalizationLP$fribbleID))-> generalizationLP$fribbleID

as.factor(gsub("/task/70033/56/asset/|/task/70033/57/asset/|/task/70033/58/asset/", "", generalizationLP$resp))-> generalizationLP$resp

as.factor(gsub(".jpg", "", generalizationLP$resp))-> generalizationLP$resp

```

Then check for duplicates:
```{r}

substr(as.character(generalizationLP$fribbleID), 1, 5)-> temp
substr(as.character(generalizationLP$fribbleID), 7, 11)-> temp2
substr(as.character(generalizationLP$fribbleID), 13, 17)-> temp3

fribblePresented <- c(temp,temp2,temp3)
unique(generalizationLP$subjID)-> subj

duplicatedFribbles <- NA;
for (i in 1:length(subj)){
  substr(as.character(generalizationLP[generalizationLP$subjID==subj[i],]$fribbleID), 1, 5)-> temp
  substr(as.character(generalizationLP[generalizationLP$subjID==subj[i],]$fribbleID), 7, 11)-> temp2
  substr(as.character(generalizationLP[generalizationLP$subjID==subj[i],]$fribbleID), 13, 17)-> temp3
  fribblePresented <- c(temp,temp2,temp3)
  dup <- fribblePresented[duplicated(fribblePresented)] #extract duplicated elements
  print(subj[i])
  
  if (length(dup)>0){
    print(dup)
  } else {
    print(length(dup))
  }
  
};

rm(subj, temp, temp2, temp3, i, fribblePresented, duplicatedFribbles, dup)
```

Great! participants saw always different fribble.

### Check whether fribbles presented were either high or low frequency within trials

In this task we have three pictures and one label pronounced. This means that the fribbleID column contains 3 images.
I'm going to cycle over the dataset, and break the fribbleID column in three, then I'm going to print the fribble that within the same trial has a different frequency. I'm going to print the fribbles that are presented wrongly, e.g., "low high low" etc. If all fribbles are presented correctly: , e.g., "low low low" and "high high high", then the output is empty. 

```{r check fribble presentation low vs high freq}
unique(generalizationLP$subjID)-> subj;

trials <- NULL;
task <- NULL;

for (i in 1:length(subj)){
  as.integer(substr(as.character(generalizationLP[generalizationLP$subjID==subj[i],]$fribbleID), 4, 5))-> temp #first fribble
  as.integer(substr(as.character(generalizationLP[generalizationLP$subjID==subj[i],]$fribbleID), 10, 11))-> temp2 #second fribble
  as.integer(substr(as.character(generalizationLP[generalizationLP$subjID==subj[i],]$fribbleID), 16, 17))-> temp3 #third fribble
trials <- cbind(temp, temp2, temp3, as.integer(subj[i])) # store it in columns along with subj info
task <- rbind(task, trials) #store all subjs
};

for (i in 1:nrow(task)){ #check by rows whether there is a unique number, print the row if wrong
  if ((task[i,1] == task[i,2] & task[i,3])== FALSE) {
    print('wrong frequency fribble:')
    print(task[i,1], task[i,2], task[i,3])
  } 
};

frequency <- ifelse(substr(as.character(task[,1]), 1, 1)==2, 'low', 'high')
cbind(task, frequency)->task
as.data.frame(task)-> task
rm(trials, i, subj, temp, temp2, temp3);
```

Great, fribbles presented were either low or high frequency.
Check whether participants saw 4 trials with low and 4 trials with high frequency:

### Check trial distribution per frequency:

```{r}
head(table(task$V4, task$frequency))
```


I'm going to merge the stimuli set now.

When we do it, this time we need to merge by resp and not by fribbleID, because our fribble selected is coded in this column:

```{r merge stimuli LP}
fribbleSet$resp <- fribbleSet$fribbleID # column's name needs to be the same in order to merge
merge(generalizationLP, fribbleSet, by = 'resp', all.x = T)-> generalizationLP;
fribbleSet$resp <- NULL;
generalizationLP$fribbleID.y <- NULL;
generalizationLP$label.y <- NULL;
generalizationLP <- rename(generalizationLP, label = label.x);
generalizationLP <- rename(generalizationLP, fribbleID = fribbleID.x);

```

### Check responses distribution by category:

```{r}
generalizationLP %>%                             
  group_by(subjID, category) %>%  
  count()
```

Cool.

### Check responses distribution by frequency:

```{r}
generalizationLP %>%                             
  group_by(subjID, label, frequency) %>%  
  count()
```


## Check test 3: Contingency Judgement task

```{r}
contingencyJudgement <- testing %>%
  filter(task == 'contingencyJudgement') 
contingencyJudgement <- droplevels(contingencyJudgement)
```

### How many trials per participant?

```{r}
contingencyJudgement %>%                             
  group_by(subjID) %>%  
  count() 
```

Very good. 

### Did participants see a fribble more than once?

```{r}
droplevels(contingencyJudgement) %>%                             
  group_by(subjID, fribbleID) %>%  
  count() %>%
  filter( n > 1)

```
No! that's great.

### Are labels repeated equally?

```{r}
table(contingencyJudgement$subjID, contingencyJudgement$label)
```

good

```{r merge stimuli contingency task} 
merge(contingencyJudgement, fribbleSet, by = 'fribbleID')-> contingencyJudgement
contingencyJudgement$label.y <- NULL;
contingencyJudgement <- rename(contingencyJudgement, label = label.x)
```

### Check category presentation:

```{r}
contingencyJudgement %>%                             
  group_by(subjID, category) %>%  
  count()
```

```{r}
table(contingencyJudgement$category, contingencyJudgement$label)

```


## Check test 4: Random dot task

Let's check our random dot task. This was inserted randomly during trials 4 times. 5 trials each time, plus 4 practice trials.


```{r random dot filter}
randomDot <- testing %>%
  filter(task == 'randomDot') 

```

### How many trials per participant?

```{r}
randomDot %>%                             
  group_by(subjID) %>%  
  count() 

```

we have 5 trials repeated during learning four times (20) plus 4 practice trials.

### How was accuracy distributed across participants?

First, let's consider that when we have a timeout, the output is -1

```{r}
randomDot %>%                             
  group_by(subjID, resp) %>% 
  filter(rt == -1) %>%
  count()

```
Here we can see that some participant missed some trials.


Let's see how accuracy is coded when response is -1:

```{r}
head(randomDot[randomDot$rt == -1,]$acc)
```

So it is coded as "NA", great. However:

```{r}
nrow(randomDot[is.na(randomDot$acc),]) #total of NA
nrow(randomDot[randomDot$resp == -1,]) # total of timeouts
```

There are more NA's in acc than can be explained by timeouts. This means that also wrong responses are coded as NA. We need to recode those.

```{r}
randomDot[is.na(randomDot$acc),]$acc <- 0 #recode everything that is wrong or timeout as 0
```

### Check the overall accuracy of participants, filtering by timeouts:

```{r timeout table}
aggregate(acc ~ subjID, data = randomDot[!(randomDot$resp == -1),], FUN = mean)# without timeouts
```

Now that we have all tests separated, better to remove this file:
```{r, echo=FALSE}
rm(testing)
```

## save data 
```{r}
write.table(generalizationLP, paste(localGitDir, "/exp1/data/generalizationLP.txt", sep = ""),
            col.names = T, row.names = F, quote = F)

write.table(generalizationPL, paste(localGitDir, "/exp1/data/generalizationPL.txt", sep = ""),
            col.names = T, row.names = F, quote = F)

write.table(contingencyJudgement, paste(localGitDir, "/exp1/data/contingencyJudgment.txt", sep = ""),
            col.names = T, row.names = F, quote = F)

write.table(randomDot, paste(localGitDir, "/exp1/data/randomDot.txt", sep = ""),
            col.names = T, row.names = F, quote = F)

write.table(raw_data, paste(localGitDir, "/exp1/data/rawData.txt", sep = ""),
            col.names = T, row.names = F, quote = F)

write.table(learning, paste(localGitDir, "/exp1/data/learning.txt", sep = ""),
            col.names = T, row.names = F, quote = F)




```

